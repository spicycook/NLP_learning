>>> for train_index, test_index in skf.split(texts_preprocessed,classes):
...     texts_preprocessed_train = [texts_preprocessed[i] for i in train_index]
...     texts_preprocessed_train_ = [texts_preprocessed_[i] for i in train_index]
...     texts_preprocessed_dev = [texts_preprocessed[i] for i in test_index]
...     texts_preprocessed_dev_ = [texts_preprocessed_[i] for i in test_index]
...     # Feature 1: n-grams
...     # VECTORIZE
...     vectorizer = CountVectorizer(ngram_range=(1, 3), analyzer="word", tokenizer=None, stop_words='english', preprocessor=None,
...                                     max_features=mx_ftr_gram)
...     vectorizer.fit(texts_preprocessed_train)
...     training_gram = vectorizer.transform(texts_preprocessed_train).toarray()
...     test_gram = vectorizer.transform(texts_preprocessed_dev).toarray()
...     # Feature 2: clusters
...     clusters_train = []; clusters_train_ = [];
...     clusters_dev = []; clusters_dev_ = [];
...     #PROGRAMMING TIP: c++ style coding here can help when doing feature engineering.. see below
...     clusters_train = getClusters(texts_preprocessed_train); clusters_dev = getClusters(texts_preprocessed_dev); 
...     clusters_train_ = getClusters(texts_preprocessed_train_); clusters_dev_ = getClusters(texts_preprocessed_dev_)
...     #VECTORIZE
...     cluster_train = clustervectorizer.fit_transform(clusters_train).toarray(); cluster_dev = clustervectorizer.transform(clusters_dev).toarray();
...     cluster_train_ = clustervectorizer.fit_transform(clusters_train_).toarray(); cluster_dev_ = clustervectorizer.transform(clusters_dev_).toarray()
...     # Combine all features together
...     training_data = np.concatenate((training_gram, cluster_train, cluster_train_, non_text_TRAIN.iloc[train_index]), axis=1)
...     test_data = np.concatenate((test_gram,cluster_dev, cluster_dev_, non_text_TRAIN.iloc[test_index]),axis=1)
...     ttp_train, ttp_test = classes[train_index], classes[test_index]
...     # training_data = formatData(non_text_TRAIN, texts_preprocessed, texts_preprocessed_, train_index, vectorizer)
...     # test_data = formatData(non_text_TRAIN, texts_preprocessed, texts_preprocessed_, test_index, vectorizer)
...     grid_params = {
...         'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Values of alpha to test
...     }
...     results, grid = search_hyperparam_space(grid_params, naive_bayes, training_data,ttp_train,test_data,ttp_test)
...     print("Best parameters set found on development set:")
...     print(grid.best_params_)
...     print("Grid scores on development set:")
...     means = grid.cv_results_['mean_test_score']
...     stds = grid.cv_results_['std_test_score']
...     for mean, std, params in zip(means, stds, grid.cv_results_['params']):
...         print("%0.3f (+/-%0.03f) for %r"
...                 % (mean, std * 2, params))
...     # TRAIN THE MODEL
...     nb_classifier = grid.best_estimator_.fit(training_data, ttp_train)
...     predictions = nb_classifier.predict(test_data)    
...     accuracy, f1_micro, f1_macro = accuracy_score(ttp_test, predictions), f1_score(ttp_test, predictions, average='micro'), f1_score(ttp_test, predictions, average='macro')
...     # Print the results
...     print(f'Accuracy: {accuracy:.2f}')
...     print(f'Micro-averaged F1 Score: {f1_micro:.2f}')
...     print(f'Macro-averaged F1 Score: {f1_macro:.2f}')
... 
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.1}
Grid scores on development set:
0.609 (+/-0.203) for {'alpha': 0.1}
0.598 (+/-0.218) for {'alpha': 0.2}
0.587 (+/-0.192) for {'alpha': 0.3}
0.587 (+/-0.192) for {'alpha': 0.4}
0.583 (+/-0.182) for {'alpha': 0.5}
0.580 (+/-0.173) for {'alpha': 0.6}
0.580 (+/-0.173) for {'alpha': 0.7}
0.580 (+/-0.173) for {'alpha': 0.8}
0.580 (+/-0.173) for {'alpha': 0.9}
0.572 (+/-0.156) for {'alpha': 1.0}
Accuracy: 0.57
Micro-averaged F1 Score: 0.57
Macro-averaged F1 Score: 0.42
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.2}
Grid scores on development set:
0.621 (+/-0.256) for {'alpha': 0.1}
0.625 (+/-0.266) for {'alpha': 0.2}
0.621 (+/-0.256) for {'alpha': 0.3}
0.621 (+/-0.256) for {'alpha': 0.4}
0.606 (+/-0.242) for {'alpha': 0.5}
0.599 (+/-0.224) for {'alpha': 0.6}
0.599 (+/-0.224) for {'alpha': 0.7}
0.592 (+/-0.218) for {'alpha': 0.8}
0.584 (+/-0.214) for {'alpha': 0.9}
0.577 (+/-0.202) for {'alpha': 1.0}
Accuracy: 0.63
Micro-averaged F1 Score: 0.63
Macro-averaged F1 Score: 0.63
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.2}
Grid scores on development set:
0.602 (+/-0.173) for {'alpha': 0.1}
0.602 (+/-0.188) for {'alpha': 0.2}
0.587 (+/-0.192) for {'alpha': 0.3}
0.591 (+/-0.203) for {'alpha': 0.4}
0.580 (+/-0.173) for {'alpha': 0.5}
0.580 (+/-0.173) for {'alpha': 0.6}
0.572 (+/-0.155) for {'alpha': 0.7}
0.572 (+/-0.155) for {'alpha': 0.8}
0.572 (+/-0.155) for {'alpha': 0.9}
0.572 (+/-0.155) for {'alpha': 1.0}
Accuracy: 0.53
Micro-averaged F1 Score: 0.53
Macro-averaged F1 Score: 0.35
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.1}
Grid scores on development set:
0.610 (+/-0.231) for {'alpha': 0.1}
0.606 (+/-0.231) for {'alpha': 0.2}
0.606 (+/-0.231) for {'alpha': 0.3}
0.592 (+/-0.207) for {'alpha': 0.4}
0.588 (+/-0.209) for {'alpha': 0.5}
0.592 (+/-0.218) for {'alpha': 0.6}
0.588 (+/-0.211) for {'alpha': 0.7}
0.588 (+/-0.211) for {'alpha': 0.8}
0.580 (+/-0.194) for {'alpha': 0.9}
0.580 (+/-0.194) for {'alpha': 1.0}
Accuracy: 0.67
Micro-averaged F1 Score: 0.67
Macro-averaged F1 Score: 0.67
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.1}
Grid scores on development set:
0.598 (+/-0.177) for {'alpha': 0.1}
0.595 (+/-0.167) for {'alpha': 0.2}
0.583 (+/-0.157) for {'alpha': 0.3}
0.572 (+/-0.141) for {'alpha': 0.4}
0.572 (+/-0.155) for {'alpha': 0.5}
0.569 (+/-0.146) for {'alpha': 0.6}
0.565 (+/-0.139) for {'alpha': 0.7}
0.565 (+/-0.139) for {'alpha': 0.8}
0.565 (+/-0.139) for {'alpha': 0.9}
0.565 (+/-0.139) for {'alpha': 1.0}
Accuracy: 0.60
Micro-averaged F1 Score: 0.60
Macro-averaged F1 Score: 0.49
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.1}
Grid scores on development set:
0.532 (+/-0.015) for {'alpha': 0.1}
0.532 (+/-0.015) for {'alpha': 0.2}
0.532 (+/-0.015) for {'alpha': 0.3}
0.528 (+/-0.017) for {'alpha': 0.4}
0.528 (+/-0.017) for {'alpha': 0.5}
0.528 (+/-0.017) for {'alpha': 0.6}
0.528 (+/-0.017) for {'alpha': 0.7}
0.528 (+/-0.017) for {'alpha': 0.8}
0.528 (+/-0.017) for {'alpha': 0.9}
0.528 (+/-0.017) for {'alpha': 1.0}
Accuracy: 0.47
Micro-averaged F1 Score: 0.47
Macro-averaged F1 Score: 0.37
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.1}
Grid scores on development set:
0.539 (+/-0.029) for {'alpha': 0.1}
0.528 (+/-0.017) for {'alpha': 0.2}
0.528 (+/-0.017) for {'alpha': 0.3}
0.528 (+/-0.017) for {'alpha': 0.4}
0.528 (+/-0.017) for {'alpha': 0.5}
0.528 (+/-0.017) for {'alpha': 0.6}
0.528 (+/-0.017) for {'alpha': 0.7}
0.528 (+/-0.017) for {'alpha': 0.8}
0.528 (+/-0.017) for {'alpha': 0.9}
0.528 (+/-0.017) for {'alpha': 1.0}
Accuracy: 0.47
Micro-averaged F1 Score: 0.47
Macro-averaged F1 Score: 0.32
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.1}
Grid scores on development set:
0.558 (+/-0.209) for {'alpha': 0.1}
0.558 (+/-0.209) for {'alpha': 0.2}
0.558 (+/-0.209) for {'alpha': 0.3}
0.551 (+/-0.199) for {'alpha': 0.4}
0.551 (+/-0.199) for {'alpha': 0.5}
0.543 (+/-0.182) for {'alpha': 0.6}
0.543 (+/-0.182) for {'alpha': 0.7}
0.540 (+/-0.169) for {'alpha': 0.8}
0.540 (+/-0.169) for {'alpha': 0.9}
0.536 (+/-0.165) for {'alpha': 1.0}
Accuracy: 0.63
Micro-averaged F1 Score: 0.63
Macro-averaged F1 Score: 0.63
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.1}
Grid scores on development set:
0.643 (+/-0.179) for {'alpha': 0.1}
0.632 (+/-0.173) for {'alpha': 0.2}
0.632 (+/-0.171) for {'alpha': 0.3}
0.617 (+/-0.158) for {'alpha': 0.4}
0.606 (+/-0.152) for {'alpha': 0.5}
0.595 (+/-0.135) for {'alpha': 0.6}
0.588 (+/-0.131) for {'alpha': 0.7}
0.588 (+/-0.131) for {'alpha': 0.8}
0.580 (+/-0.116) for {'alpha': 0.9}
0.569 (+/-0.110) for {'alpha': 1.0}
Accuracy: 0.57
Micro-averaged F1 Score: 0.57
Macro-averaged F1 Score: 0.47
CountVectorizer(max_features=3000, ngram_range=(1, 3), stop_words='english')
Best parameters set found on development set:
{'alpha': 0.1}
Grid scores on development set:
0.652 (+/-0.207) for {'alpha': 0.1}
0.633 (+/-0.223) for {'alpha': 0.2}
0.633 (+/-0.223) for {'alpha': 0.3}
0.630 (+/-0.213) for {'alpha': 0.4}
0.626 (+/-0.205) for {'alpha': 0.5}
0.604 (+/-0.188) for {'alpha': 0.6}
0.600 (+/-0.181) for {'alpha': 0.7}
0.600 (+/-0.181) for {'alpha': 0.8}
0.593 (+/-0.169) for {'alpha': 0.9}
0.589 (+/-0.174) for {'alpha': 1.0}
Accuracy: 0.52
Micro-averaged F1 Score: 0.52
Macro-averaged F1 Score: 0.34